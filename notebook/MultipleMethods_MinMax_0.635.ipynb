{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 done...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "#import data from files\n",
    "\n",
    "x_header = pd.read_csv(\"x_header.csv\")\n",
    "train_data = pd.read_csv('train_data.csv', header = None)\n",
    "test_data = pd.read_csv('test_data.csv', header = None)\n",
    "train_labels = pd.read_csv('train_labels.csv', header = None, dtype = 'category' )\n",
    "\n",
    "\n",
    "#create variables \n",
    "header = pd.DataFrame(data = x_header)\n",
    "X = pd.DataFrame(data = train_data)\n",
    "X.columns = header.ID\n",
    "X_test = pd.DataFrame(data = test_data)\n",
    "X_test.columns = header.ID\n",
    "y = pd.DataFrame(data = train_labels)\n",
    "y.columns = ['Genre']\n",
    "\n",
    "print(\"Part 1 done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 done...\n"
     ]
    }
   ],
   "source": [
    "#Merge X and X_test\n",
    "\n",
    "X = pd.concat([X,X_test])\n",
    "\n",
    "#View value frequencies from each columns \n",
    "#for i in X.columns:\n",
    "#    print(\"Value count\", i, \": \", X[i].value_counts().head(5))\n",
    "#Drop bad data\n",
    "\n",
    "X = X.drop(columns = ['MFCC_Mean_1','MFCC_Mean_2','MFCC_Mean_3','MFCC_Mean_4','MFCC_Min_1'])\n",
    "#Normalize data according to group\n",
    "#display(HTML(x_y_train.head(15).to_html(max_rows=15)))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_test = X[4363:]\n",
    "X = X[:4363]\n",
    "\n",
    "print(\"Part 2 done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to test-validation set\n",
    "def run_model(model, alg_name, test_size):\n",
    "    global X\n",
    "    global y\n",
    "    global X_train, X_val, y_train, y_val\n",
    "    y = np.ravel(y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"----\",alg_name,\"----\")\n",
    "    print(model.score(X_train,y_train))\n",
    "    print(model.score(X_val,y_val))\n",
    "    #Apply cross validation\n",
    "    scores = cross_validate(model, X_train, y_train, cv=3)\n",
    "    print(\"Cross-validated scores:\", scores[\"test_score\"])\n",
    "\n",
    "#try this  https://www.kaggle.com/coolman/different-classification-techniques-python\n",
    "#Neural network results highest score\n",
    "# ----------- Neural network - Multi-layer Perceptron  ------------\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#model = MLPClassifier()\n",
    "#run_model(model, \" MLP Neural network default\", 0.2)\n",
    "\n",
    "#model1 = MLPClassifier()\n",
    "#run_model(model1, \" MLP Neural network default\", 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "indx = range(y_test_pred.shape[0])\n",
    "result = pd.DataFrame(index = indx, columns = [\"Sample_id\",\"Sample_label\"])\n",
    "result[\"Sample_id\"] = result.index+1\n",
    "result[\"Sample_label\"] = y_test_pred\n",
    "result.to_csv(\"MLPClassifier_MinMaxScaler_test20.csv\", index = False)\n",
    "\n",
    "y_test_pred = model1.predict(X_test)\n",
    "indx = range(y_test_pred.shape[0])\n",
    "result = pd.DataFrame(index = indx, columns = [\"Sample_id\",\"Sample_label\"])\n",
    "result[\"Sample_id\"] = result.index+1\n",
    "result[\"Sample_label\"] = y_test_pred\n",
    "result.to_csv(\"MLPClassifier__MinMaxScaler_test30.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Random Forest ----\n",
      "0.994193154034\n",
      "0.597616865261\n",
      "Cross-validated scores: [ 0.58096981  0.5472044   0.59007353]\n",
      "---- XGBoost ----\n",
      "0.880195599022\n",
      "0.658111824015\n",
      "Cross-validated scores: [ 0.63129003  0.61136572  0.61672794]\n"
     ]
    }
   ],
   "source": [
    "#Other models \n",
    "\n",
    "# ----- Random Forest ---------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model4 = RandomForestClassifier(n_estimators=15)\n",
    "run_model(model4, \"Random Forest\", 0.25)\n",
    "\n",
    "# ----- xgboost ------------\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "modelxg = XGBClassifier(max_depth = 3, objective = 'multi:softmax')\n",
    "run_model(modelxg, \"XGBoost\",0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "conf_mat = confusion_matrix(y_true=y_val, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model1.predict(X_val)\n",
    "conf_mat = confusion_matrix(y_true=y_val, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
